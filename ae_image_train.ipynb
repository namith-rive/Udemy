{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jcu3O9ZxDkRxjLlp6nPzi4YEAjk6yWSA",
      "authorship_tag": "ABX9TyMFWaJW+NOjp4Smzb31CkA3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namith-rive/Udemy/blob/main/ae_image_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ae_image_train"
      ],
      "metadata": {
        "id": "uy2zv6lH2_Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# 実行方法　python3 this.py Datafoler\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras.models\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "# tensorflow 2.9.1以降, tensorflow-gpu 2.0.0以降の場合、前行の代わりに次行を使ってください\n",
        "# from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# 入力データサイズ\n",
        "INPUT_SIZE = 64\n",
        "IMAGE_CHANNEL = 3\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "#ModelFile = \"./ae_image_model.h5\"\n",
        "ModelFile = '/content/drive/MyDrive/sample_image/ae_image_model.h5'\n",
        "\n",
        "# 学習用データの読み込み\n",
        "#args = sys.argv\n",
        "#Datafolder = args[1]\n",
        "Datafolder = '/content/drive/MyDrive/sample_image/image_train'\n",
        "if not os.path.exists(Datafolder):\n",
        "    print(\"Datafolder not exist.\")\n",
        "    exit()\n",
        "\n",
        "# フォルダ配下の画像を全て読み込む\n",
        "IMAGES = []\n",
        "Datafiles = Datafolder + '/*.jpg'\n"
      ],
      "metadata": {
        "id": "WtYoVxwt9p3n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array\n",
        "\n",
        "# 1枚あたり10枚の画像を水増し\n",
        "N_img = 10\n",
        "\n",
        "files = glob.glob(Datafiles)\n",
        "for i, file in enumerate(files):\n",
        "\n",
        "    img = load_img(file)\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # ImageDataGeneratorの生成\n",
        "    datagen = ImageDataGenerator(\n",
        "    zca_epsilon=1e-06,   # 白色化のイプシロン\n",
        "    rotation_range=10.0, # ランダムに回転させる範囲\n",
        "    width_shift_range=0.0, # ランダムに幅をシフトさせる範囲\n",
        "    height_shift_range=0.0, # ランダムに高さをシフトさせる範囲\n",
        "    brightness_range=None, # ランダムに明るさを変化させる範囲\n",
        "    zoom_range=0.0,        # ランダムにズームさせる範囲\n",
        "    horizontal_flip=True, # ランダムに水平方向に反転させる\n",
        "    vertical_flip=True, # ランダムに垂直方向に反転させる\n",
        "    )\n",
        "\n",
        "    # 画像を水増し生成\n",
        "    dg = datagen.flow(x, batch_size=1, save_to_dir=Datafolder, save_prefix='img', save_format='jpg')\n",
        "    for i in range(N_img):\n",
        "        batch = dg.next()"
      ],
      "metadata": {
        "id": "X932fXNd9tlZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for pic in glob.glob(Datafiles):\n",
        "    img = img_to_array(load_img(pic, target_size=(INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL)))\n",
        "    IMAGES.append(img)\n",
        "# arrayに変換\n",
        "IMAGES = np.array(IMAGES)\n",
        "# 画素値を0から1の範囲に変換\n",
        "IMAGES = IMAGES.astype('float32')\n",
        "train_data = IMAGES / 255.0\n",
        "print('Number of Images: ', len(train_data))\n",
        "\n",
        "# AutoEncoder + Convolution モデルの組み立て\n",
        "model = Sequential()\n",
        "\n",
        "# 3*3フィルタ32枚をゼロパディングで埋めて畳み込む\n",
        "model.add(Conv2D(int(INPUT_SIZE/2), (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(int(INPUT_SIZE/4), (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(int(INPUT_SIZE/4), (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(int(INPUT_SIZE/2), (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(IMAGE_CHANNEL, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.build((BATCH_SIZE, INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL))\n",
        "model.summary()\n",
        "\n",
        "# 学習：入力データと結果データを同一にする\n",
        "history = model.fit(x=train_data, y=train_data,\n",
        "                             epochs=100,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             validation_split=0.1)\n",
        "\n",
        "\n",
        "# 学習済みモデルを保存\n",
        "model.save(ModelFile)\n",
        "print('Model saved.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CPhv_cG286c",
        "outputId": "510d37e4-b40c-43f6-ec86-6df8e952d6f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images:  347\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (2, 64, 64, 32)           896       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (2, 64, 64, 32)           128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (2, 64, 64, 32)           0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (2, 32, 32, 32)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (2, 32, 32, 16)           4624      \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (2, 32, 32, 16)           64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (2, 32, 32, 16)           0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (2, 16, 16, 16)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (2, 16, 16, 16)           2320      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (2, 16, 16, 16)           64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (2, 16, 16, 16)           0         \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (2, 32, 32, 16)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (2, 32, 32, 32)           4640      \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (2, 32, 32, 32)           128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_8 (Activation)   (2, 32, 32, 32)           0         \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSamplin  (2, 64, 64, 32)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (2, 64, 64, 3)            867       \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (2, 64, 64, 3)            12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_9 (Activation)   (2, 64, 64, 3)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13743 (53.68 KB)\n",
            "Trainable params: 13545 (52.91 KB)\n",
            "Non-trainable params: 198 (792.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "156/156 [==============================] - 3s 7ms/step - loss: 0.0249 - val_loss: 0.0332\n",
            "Epoch 2/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0145 - val_loss: 0.0226\n",
            "Epoch 3/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0107 - val_loss: 0.0148\n",
            "Epoch 4/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0105\n",
            "Epoch 5/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0083 - val_loss: 0.0072\n",
            "Epoch 6/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 7/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0066\n",
            "Epoch 8/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0059\n",
            "Epoch 9/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0058\n",
            "Epoch 10/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0059\n",
            "Epoch 11/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0057\n",
            "Epoch 12/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0061\n",
            "Epoch 13/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0053\n",
            "Epoch 14/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0048\n",
            "Epoch 15/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 16/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0053\n",
            "Epoch 17/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0046\n",
            "Epoch 18/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0043\n",
            "Epoch 19/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0040\n",
            "Epoch 20/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0040\n",
            "Epoch 21/100\n",
            "156/156 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0039\n",
            "Epoch 22/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0038\n",
            "Epoch 23/100\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.0047 - val_loss: 0.0041\n",
            "Epoch 24/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0044\n",
            "Epoch 25/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0036\n",
            "Epoch 26/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0038\n",
            "Epoch 27/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0037\n",
            "Epoch 28/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0038\n",
            "Epoch 29/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0041\n",
            "Epoch 30/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0035\n",
            "Epoch 31/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0038\n",
            "Epoch 32/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0036\n",
            "Epoch 33/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0036\n",
            "Epoch 34/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0036\n",
            "Epoch 35/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0039\n",
            "Epoch 36/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0037\n",
            "Epoch 37/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0038\n",
            "Epoch 38/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0037\n",
            "Epoch 39/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0033\n",
            "Epoch 40/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
            "Epoch 41/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 42/100\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 43/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0036\n",
            "Epoch 44/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0037\n",
            "Epoch 45/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
            "Epoch 46/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0032\n",
            "Epoch 47/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 48/100\n",
            "156/156 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0036\n",
            "Epoch 49/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 50/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 51/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0035\n",
            "Epoch 52/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0038\n",
            "Epoch 53/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0033\n",
            "Epoch 54/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0033\n",
            "Epoch 55/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0033\n",
            "Epoch 56/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0031\n",
            "Epoch 57/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0032\n",
            "Epoch 58/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
            "Epoch 59/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0039\n",
            "Epoch 60/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0032\n",
            "Epoch 61/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0033\n",
            "Epoch 62/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0033\n",
            "Epoch 63/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0032\n",
            "Epoch 64/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 65/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 66/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 67/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
            "Epoch 68/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
            "Epoch 69/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0033\n",
            "Epoch 70/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0031\n",
            "Epoch 71/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 72/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0032\n",
            "Epoch 73/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0031\n",
            "Epoch 74/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0033\n",
            "Epoch 75/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0031\n",
            "Epoch 76/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0031\n",
            "Epoch 77/100\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0036\n",
            "Epoch 78/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0032\n",
            "Epoch 79/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0034\n",
            "Epoch 80/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0038\n",
            "Epoch 81/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0033\n",
            "Epoch 82/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0034\n",
            "Epoch 83/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0035\n",
            "Epoch 84/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
            "Epoch 85/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0031\n",
            "Epoch 86/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
            "Epoch 87/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0030\n",
            "Epoch 88/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0030\n",
            "Epoch 89/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0030\n",
            "Epoch 90/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0032\n",
            "Epoch 91/100\n",
            "156/156 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0037\n",
            "Epoch 92/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0031\n",
            "Epoch 93/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0030\n",
            "Epoch 94/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0030\n",
            "Epoch 95/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0030\n",
            "Epoch 96/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0033\n",
            "Epoch 97/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0034\n",
            "Epoch 98/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0030\n",
            "Epoch 99/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0031\n",
            "Epoch 100/100\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0032\n",
            "Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVQCfs1303or",
        "outputId": "a74bdca1-bbbf-4836-f42b-e4498e954de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d4a66cbb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 128ms/step\n",
            "Score:  0.0023131517\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Score:  0.0041914363\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# 実行方法　python3 this.py datafile\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import keras.models\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "# tensorflow 2.9.1以降, tensorflow-gpu 2.0.0以降の場合、前行の代わりに次行を使ってください\n",
        "# from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# 入力データサイズ\n",
        "INPUT_SIZE = 64\n",
        "IMAGE_CHANNEL = 3\n",
        "\n",
        "#ModelFile = \"./ae_image_model.h5\"\n",
        "\n",
        "if not os.path.exists(ModelFile):\n",
        "    print(\"Modelfile not exist.\")\n",
        "    exit()\n",
        "\n",
        "#args = sys.argv\n",
        "#Datafile = args[1]\n",
        "Datafile = '/content/drive/MyDrive/sample_image/image_detect/bolt_normal.jpg'\n",
        "Datafile2 = '/content/drive/MyDrive/sample_image/image_detect/bolt_anomaly.jpg'\n",
        "\n",
        "if not os.path.exists(Datafile):\n",
        "    print(\"Datafile not exist.\")\n",
        "    exit()\n",
        "\n",
        "model = keras.models.load_model(ModelFile)\n",
        "\n",
        "#正常画像\n",
        "img = img_to_array(load_img(Datafile, target_size=(INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL)))\n",
        "# arrayに変換\n",
        "img = np.array(img)\n",
        "img = img.reshape(1, INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL)\n",
        "# 画素値を0から1の範囲に変換\n",
        "img = img.astype('float32')\n",
        "detect_data = img / 255.0\n",
        "\n",
        "detect_pred = model.predict(detect_data)\n",
        "\n",
        "detect_score = np.mean(np.square(detect_data - detect_pred), axis=1)\n",
        "detect_score = np.average(detect_score)\n",
        "print('Score: ', detect_score)\n",
        "\n",
        "# 異常画像\n",
        "img = img_to_array(load_img(Datafile2, target_size=(INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL)))\n",
        "# arrayに変換\n",
        "img = np.array(img)\n",
        "img = img.reshape(1, INPUT_SIZE, INPUT_SIZE, IMAGE_CHANNEL)\n",
        "# 画素値を0から1の範囲に変換\n",
        "img = img.astype('float32')\n",
        "detect_data = img / 255.0\n",
        "\n",
        "detect_pred = model.predict(detect_data)\n",
        "\n",
        "detect_score = np.mean(np.square(detect_data - detect_pred), axis=1)\n",
        "detect_score = np.average(detect_score)\n",
        "print('Score: ', detect_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1/1 [==============================] - 0s 111ms/step\n",
        "\n",
        "Score:  0.0033047695\n",
        "\n",
        "1/1 [==============================] - 0s 19ms/step\n",
        "\n",
        "Score:  0.010835145"
      ],
      "metadata": {
        "id": "UqmEjYUe_rG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efgrmw-O7Sdc",
        "outputId": "de8704f1-869c-4843-8309-6dec3e2b05f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoJWbf9t4nTk",
        "outputId": "8374670d-8020-4933-fce2-2f79a4ac1629"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQCkEuc86tZL",
        "outputId": "a1506e8d-8f06-4692-c724-7949ebb3cc30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[165., 166., 158.],\n",
              "        [167., 167., 157.],\n",
              "        [172., 170., 158.],\n",
              "        ...,\n",
              "        [165., 162., 153.],\n",
              "        [158., 158., 150.],\n",
              "        [162., 163., 157.]],\n",
              "\n",
              "       [[165., 166., 158.],\n",
              "        [163., 163., 153.],\n",
              "        [165., 163., 151.],\n",
              "        ...,\n",
              "        [165., 162., 153.],\n",
              "        [158., 159., 151.],\n",
              "        [157., 160., 153.]],\n",
              "\n",
              "       [[168., 169., 161.],\n",
              "        [168., 168., 158.],\n",
              "        [168., 168., 158.],\n",
              "        ...,\n",
              "        [166., 164., 152.],\n",
              "        [166., 163., 154.],\n",
              "        [160., 160., 150.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[163., 163., 153.],\n",
              "        [164., 165., 149.],\n",
              "        [163., 164., 148.],\n",
              "        ...,\n",
              "        [166., 164., 149.],\n",
              "        [167., 165., 150.],\n",
              "        [165., 163., 148.]],\n",
              "\n",
              "       [[167., 167., 157.],\n",
              "        [168., 169., 153.],\n",
              "        [168., 169., 153.],\n",
              "        ...,\n",
              "        [163., 162., 144.],\n",
              "        [165., 164., 146.],\n",
              "        [164., 163., 145.]],\n",
              "\n",
              "       [[161., 161., 151.],\n",
              "        [161., 162., 146.],\n",
              "        [165., 166., 150.],\n",
              "        ...,\n",
              "        [162., 161., 143.],\n",
              "        [163., 162., 144.],\n",
              "        [162., 161., 143.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avlEr4No6vot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}